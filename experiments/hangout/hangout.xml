<?xml version="1.0" encoding="UTF-8"?>
        <ModulePrefs title="Nikolaj' s Hangout Starter" height="200" width="550">
                <Require feature="rpc" />
                <Require feature="views" />
                <Require feature="locked-domain" />
        </ModulePrefs>
        <Content type="html"><![CDATA[     
<!DOCTYPE html>
          
<style type="text/css">
<!--
.button {
  border-radius: 3px;
  -moz-border-radius: 3px;
  background: -webkit-gradient(linear, left top, left bottom, from(#fff), to(#ddd));
  background: -moz-linear-gradient(top, #fff, #ddd);
  background: -ms-linear-gradient(top, #fff, #ddd);   
  background: -o-linear-gradient(top, #fff, #ddd);   
  border: 1px solid #bbb;
}
.button:active {
        background: -webkit-gradient(linear, left top, left bottom, from(#aaa), to(#333)); 
        background: -moz-linear-gradient(bottom, #ddd, #aaa); 
    background: -ms-linear-gradient(top, #fff, #ddd);   
    background: -o-linear-gradient(top, #fff, #ddd);   
}
#wrap {
    width:900px;
    margin:0 auto;
    background:#EEEEEE;
}   
#main {
    float:left;
    width:600px;
    margin:0 auto;
    background:#FFFFFF;
}
#text {
    float:right;
    width:250px;
    margin-left:10px;
    margin-top:30px;
    background:#FFFFFF;
    font-family: sans-serif;
}

-->
</style>

<link href='https://fonts.googleapis.com/css?family=Open+Sans&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
<style>

</style>
<script src="https://talkgadget.google.com/hangouts/_/api/hangout.js?v=1.4" ></script>

<div id='wrap'>
    <div id='text'>
        <input type='checkbox'
            value='true' 
            id='mirror'
            checked='true'
            onClick='onMirrorClicked()'>Mirror?</input>
        <p>This demo demonstrates the Hangouts API face movement endpoints.</p>
        <p>Each of the points represents a location on your face; note that
        the 'mouth' is really the center of your mouth and your upper lip, not a
        a complete rendering of your mouth state.</p>
        <p>Roll, pan, and tilt represent your head orientation.</p>
        <p>Your own video feed is mirrored to you, but the face data is
        as you are seen.  Check the checkbox to mirror and unmirror your data.</p>
    </div>
</div>
<script>

// Keep track of this
var canvas = document.getElementById('canvas');

// Keep track of recent events.
var lastGoodEvent;
var lastEvent;

// Are we mirroring our face render?
var mirrored = true;


/** Draws the roll, pan, and tilt of your head. */
function drawRollPanTilt(event, bright) {
    var context = canvas.getContext('2d');
    // Draw eyes
    if (bright) {
        context.strokeStyle = '#FF0000';
        context.fillStyle = '#FF0000';
    } else {
        context.strokeStyle = '#555555';
        context.fillStyle = '#555555';      
    }

    context.setTransform(1,0,0,1,0,0);

    context.translate(300, 345);
    context.beginPath();
    context.arc(0, 0, 10, 0, 2 * Math.PI);
    context.stroke();

    context.font = '24pt Arial';
    context.textAlign = 'center';
    
    var arrowScale = 100;
    context.translate(-200, 0);
    context.fillText("Roll", 0, -10);
    context.beginPath();
    context.arc(0, 0, arrowScale/2, 0, 2*Math.PI);
    context.stroke();
    context.beginPath();
    context.moveTo(-Math.cos(event.roll) * arrowScale/2,
        -Math.sin(event.roll) * arrowScale/2);
    context.lineTo(Math.cos(event.roll) * arrowScale/2,
        Math.sin(event.roll) * arrowScale/2);
    context.stroke();

    var sign = event.pan > 0 ? -1 : 1;
    context.translate(200, 0);
    context.fillText("Pan", 0, -10);
    context.beginPath();
    context.moveTo(0,0);
    context.lineTo(event.pan * arrowScale, 0);
    context.lineTo(event.pan * arrowScale + sign * 10, 10);
    context.lineTo(event.pan * arrowScale + sign * 10, -10);
    context.lineTo(event.pan * arrowScale, 0);
    context.stroke();

    sign = event.tilt < 0 ? -1 : 1;
    context.translate(200, 0);
    context.textAlign = 'left';
    context.fillText("Tilt", 10, -10);
    context.beginPath();
    context.moveTo(0,0);
    context.lineTo(0, -event.tilt * arrowScale);
    context.lineTo(10, -event.tilt * arrowScale + sign * 10);
    context.lineTo(-10, -event.tilt * arrowScale + sign * 10);
    context.lineTo(0, -event.tilt * arrowScale);
    context.stroke();
}

/** Per-frame render */
function drawFrame() {
    var context = canvas.getContext('2d');

    // Clear the canvas
    context.setTransform(1,0,0,1,0,0);
    context.fillStyle = 'rgb(0,0,0)';
    context.fillRect(0,0,600,400);

    if (lastGoodEvent) {
        drawFace(lastGoodEvent, lastEvent.hasFace);
        drawRollPanTilt(lastGoodEvent, lastEvent.hasFace);
    }
}

/** Animation loop */
function animate(){
    drawFrame();
    // request new frame
    requestAnimFrame(function () {
        animate();
    });
}

/** Standard requestAnimFrame from paulirish.com, running 30 fps */
window.requestAnimFrame = (function (callback) {
    return window.requestAnimationFrame ||
    window.webkitRequestAnimationFrame ||
    window.mozRequestAnimationFrame ||
    window.oRequestAnimationFrame ||
    window.msRequestAnimationFrame ||
    function(callback){
        window.setTimeout(callback, 1000 / 30);
    };
})();

/** Event handler */
function onFaceTrackingChanged(event) {
    try {
        lastEvent = event;
        if (event.hasFace) {
            lastGoodEvent = event;
        }
    } catch(e) {
        console.log("onFaceTrackingChanged: ERROR");
        console.log(e);
    }
}

/** Sets up event handler and shows a topHat
 * from the Media app to indicate who is the current
 * face tracked.
 */
function startHeadTracking() {
    // Create hat overlay.
    //var topHat = gapi.hangout.av.effects.createImageResource(
        'http://hangoutmediastarter.appspot.com/static/topHat.png');
    /*var overlay = topHat.createFaceTrackingOverlay(
        {'trackingFeature':
         gapi.hangout.av.effects.FaceTrackingFeature.NOSE_ROOT,
         'scaleWithFace': true,
         'rotateWithFace': true,
         'scale': 1.0});*/
    //overlay.setVisible(true);

    // Add event handler.
    //gapi.hangout.av.effects.onFaceTrackingDataChanged.
    //    add(onFaceTrackingChanged);

    console.log('Started head tracking');    
}

function init() {
  // When API is ready...                                                
  gapi.hangout.onApiReady.add(
      function(eventObj) {
        if (eventObj.isApiReady) {
            startHeadTracking();
            animate();
        }
      });
}

// Wait for gadget to load.                                         
gadgets.util.registerOnLoadHandler(init);
</script>
<br/>
]]></Content></Module>

